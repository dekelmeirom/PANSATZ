{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb18010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit import Aer, transpile, assemble\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from typing import Optional, List, Dict, Tuple, Union\n",
    "from qiskit.result import Counts, Result\n",
    "\n",
    "from qiskit import pulse, IBMQ\n",
    "from qiskit.pulse.schedule import ScheduleBlock\n",
    "from qiskit.pulse import Schedule\n",
    "from qiskit.pulse.instructions import Call\n",
    "from qiskit import transpile, schedule as build_schedule\n",
    "from qiskit.providers.aer.pulse import duffing_system_model\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# imports for qiskit dynamics simulation\n",
    "from matplotlib import pyplot as plt\n",
    "from qiskit_dynamics.pulse import InstructionToSignals\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit_dynamics import Solver\n",
    "from qiskit.quantum_info.states import Statevector\n",
    "\n",
    "# optimizers\n",
    "import random\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.algorithms.optimizers import QNSPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ccaec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numpy 1.16 has memory leak bug  https://github.com/numpy/numpy/issues/13808\n",
      "It is recommended to downgrade to numpy 1.15 or older\n"
     ]
    }
   ],
   "source": [
    "from qiskit_nature.drivers import UnitsType, Molecule\n",
    "from qiskit_nature.drivers.second_quantization import (\n",
    "    ElectronicStructureDriverType,\n",
    "    ElectronicStructureMoleculeDriver,\n",
    ")\n",
    "from qiskit_nature.problems.second_quantization import ElectronicStructureProblem\n",
    "from qiskit_nature.converters.second_quantization import QubitConverter\n",
    "from qiskit_nature.mappers.second_quantization import JordanWignerMapper, ParityMapper, BravyiKitaevMapper\n",
    "# Solvers\n",
    "from qiskit.algorithms import NumPyMinimumEigensolver\n",
    "from qiskit_nature.algorithms import GroundStateEigensolver\n",
    "\n",
    "# for HF calculation\n",
    "from pyscf import scf\n",
    "from pyscf import gto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14898930",
   "metadata": {},
   "source": [
    "# Define the system Hamiltonian\n",
    "We define the parameters of a duffling oscillator - which represent a superconducting based quantum computers.\n",
    "\n",
    "The parameters used are relevant for a fixed frequency computers, like those used by IBM. 3 energy levels are taken into account in the simulation to simulate also leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94ebc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.providers.fake_provider import FakeManila\n",
    "backend_manila = FakeManila()\n",
    "manila_backend_config = backend_manila.configuration()\n",
    "manila_ham_params = manila_backend_config.hamiltonian['vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b02b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies for transmon drift terms, harmonic term and anharmonic term\n",
    "# Number of oscillators in the model is determined from len(oscillator_freqs)\n",
    "manila_oscillator_freqs_2q = [manila_ham_params['wq0'] / (np.pi *2e9), \n",
    "                       manila_ham_params['wq1'] / (np.pi *2e9)] # numbers are in Ghz\n",
    "manila_anharm_freqs_2q = [manila_ham_params['delta0'] / (np.pi *2e9),\n",
    "                   manila_ham_params['delta1'] / (np.pi *2e9)] # numbers are in Ghz\n",
    "\n",
    "# drive strengths\n",
    "manila_drive_strengths_2q = [manila_ham_params['omegad0'] / (np.pi *2e9),\n",
    "                      manila_ham_params['omegad1'] / (np.pi *2e9)] # numbers are in Ghz\n",
    "\n",
    "# specify coupling as a dictionary\n",
    "manila_coupling_dict_2q = {(0,1): manila_ham_params['jq0q1'] / (np.pi *2e9)} # numbers are in Ghz\n",
    "\n",
    "# sample duration for pulse instructions\n",
    "dt = 0.222 # numbers are in nano-seconds\n",
    "\n",
    "# create the model\n",
    "manila_model_3levels = duffing_system_model(dim_oscillators=3,\n",
    "                                       oscillator_freqs=manila_oscillator_freqs_2q,\n",
    "                                       anharm_freqs=manila_anharm_freqs_2q,\n",
    "                                       drive_strengths=manila_drive_strengths_2q,\n",
    "                                       coupling_dict=manila_coupling_dict_2q,\n",
    "                                       dt=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d09d6e",
   "metadata": {},
   "source": [
    "# Define functions to run the simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad616872",
   "metadata": {},
   "source": [
    "### translate pulses to driving signals and run a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb9df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy(N, offset=0):\n",
    "    \"\"\"Destruction (lowering) operator.\n",
    "    Args:\n",
    "        N (int): Dimension of Hilbert space.\n",
    "        offset (int): (default 0) The lowest number state that is included\n",
    "                      in the finite number state representation of the operator.\n",
    "    Returns:\n",
    "        Qobj: Qobj for lowering operator.\n",
    "    Raises:\n",
    "        ValueError: Invalid input.\n",
    "    \"\"\"\n",
    "    if not isinstance(N, (int, np.integer)):  # raise error if N not integer\n",
    "        raise ValueError(\"Hilbert space dimension must be integer value\")\n",
    "    data = np.sqrt(np.arange(offset + 1, N + offset, dtype=complex))\n",
    "    ind = np.arange(1, N, dtype=np.int32)\n",
    "    ptr = np.arange(N + 1, dtype=np.int32)\n",
    "    ptr[-1] = N - 1\n",
    "    return csr_matrix((data, ind, ptr), shape=(N, N)).toarray()\n",
    "\n",
    "def create(N, offset=0):\n",
    "    temp = destroy(N, offset)\n",
    "    return temp.transpose().conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf456331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ansatz(system_model, pulses, dt=0.222, initial_state=None, decoherence=False):\n",
    "    hamiltonian_model = system_model.hamiltonian\n",
    "\n",
    "    static_ham = \\\n",
    "    np.pi * (2 * hamiltonian_model._variables['v0'] - hamiltonian_model._variables['alpha0'])\\\n",
    "        * hamiltonian_model._system[0][0] + \\\n",
    "    np.pi * (2 * hamiltonian_model._variables['v1'] - hamiltonian_model._variables['alpha1'])\\\n",
    "        * hamiltonian_model._system[1][0] + \\\n",
    "    np.pi * hamiltonian_model._variables['alpha0'] * hamiltonian_model._system[2][0] +\\\n",
    "    np.pi * hamiltonian_model._variables['alpha1'] * hamiltonian_model._system[3][0] +\\\n",
    "    2 * np.pi * hamiltonian_model._variables['j01'] * hamiltonian_model._system[4][0]\n",
    "  \n",
    "    carrier_freqs = []\n",
    "    ham_operators = []\n",
    "    for channel in pulses.channels:\n",
    "        if channel.name == 'd0':\n",
    "            carrier_freqs.append(hamiltonian_model._variables['v0'])\n",
    "            ham_operators.append(2 * np.pi * hamiltonian_model._variables['r0'] * \\\n",
    "                                   hamiltonian_model._system[5][0]) #D0\n",
    "        elif channel.name == 'd1':\n",
    "            carrier_freqs.append(hamiltonian_model._variables['v1'])\n",
    "            ham_operators.append(2 * np.pi * hamiltonian_model._variables['r1'] * \\\n",
    "                                   hamiltonian_model._system[6][0]) #D1\n",
    "        elif channel.name == 'u0':\n",
    "            carrier_freqs.append(hamiltonian_model._variables['v1'])\n",
    "            # CR parameters taken from hamiltonian tomography of the device\n",
    "            a1 = -6\n",
    "            a2 = 0.04\n",
    "            a3 = -0.2\n",
    "            \n",
    "            XZ = np.kron((destroy(3) + create(3)), 0.5 * np.eye(3) - (create(3) @ destroy(3)))\n",
    "            IZ = np.kron(np.eye(3), 0.5 * np.eye(3) - (create(3) @ destroy(3)))\n",
    "            XI = np.kron((create(3) + destroy(3)), np.eye(3))\n",
    "            \n",
    "            ham_operators.append(hamiltonian_model._variables['r0'] * \\\n",
    "                                (a1 * IZ +\n",
    "                                 a2 * XI + \\\n",
    "                                 a3 * XZ))\n",
    "        elif channel.name == 'u1':\n",
    "            carrier_freqs.append(hamiltonian_model._variables['v0'])\n",
    "            \n",
    "            a1 = -6\n",
    "            a2 = 0.04\n",
    "            a3 = -0.2\n",
    "            \n",
    "            ZX = np.kron(0.5 * np.eye(3) - (create(3) @ destroy(3)), (destroy(3) + create(3)))\n",
    "            ZI = np.kron(0.5 * np.eye(3) - (create(3) @ destroy(3)), np.eye(3))\n",
    "            IX = np.kron(np.eye(3), (create(3) + destroy(3)))\n",
    "            \n",
    "            ham_operators.append(hamiltonian_model._variables['r0'] * \\\n",
    "                                (a1 * ZI +\n",
    "                                 a2 * IX + \\\n",
    "                                 a3 * ZX))\n",
    "\n",
    "    signal_converter = InstructionToSignals(dt, carriers=carrier_freqs)\n",
    "\n",
    "    try:\n",
    "        ansatz_signals = signal_converter.get_signals(pulses)\n",
    "    except:\n",
    "        print(\"error in converting signal\")\n",
    "        print(pulses)\n",
    "    \n",
    "    dissipators_operators = []\n",
    "    if decoherence:\n",
    "        num_qubits = 2\n",
    "        T1 = 100000\n",
    "        T2 = 100000\n",
    "        gamma_1 = 1 / T1\n",
    "        gamma_2 = (1 / T2 + gamma_1 /2 ) /2\n",
    "        X = create(3) + destroy(3) # extension to Operator.from_label('X')\n",
    "        Y = 1j * (create(3) - destroy(3)) # extension to Operator.from_label('Y')\n",
    "        Z = destroy(3) @ create(3) - create(3) @ destroy(3) # extension to Operator.from_label('Z')\n",
    "        s_p = 0.5 * (X + 1j * Y)\n",
    "\n",
    "        for qubit in range(num_qubits):\n",
    "            zeros = Operator(np.zeros((3 ** num_qubits, 3 ** num_qubits)), \n",
    "                             input_dims=[3]*num_qubits, output_dims=[3]*num_qubits)\n",
    "            dissipators_operators.append(zeros + Operator(np.sqrt(gamma_1) * s_p)(qubit))\n",
    "            dissipators_operators.append(zeros + Operator(np.sqrt(gamma_2) * Z)(qubit))\n",
    "            \n",
    "        hamiltonian_solver = Solver(\n",
    "            static_hamiltonian=static_ham,\n",
    "            hamiltonian_operators=ham_operators,\n",
    "            hamiltonian_signals=ansatz_signals,\n",
    "            static_dissipators=dissipators_operators,\n",
    "            rotating_frame=static_ham,\n",
    "            rwa_cutoff_freq=2*hamiltonian_model._variables['v1']\n",
    "        )\n",
    "                        \n",
    "    else:\n",
    "        hamiltonian_solver = Solver(\n",
    "            static_hamiltonian=static_ham,\n",
    "            hamiltonian_operators=ham_operators,\n",
    "            hamiltonian_signals=ansatz_signals,\n",
    "            rotating_frame=static_ham,\n",
    "            rwa_cutoff_freq=2*hamiltonian_model._variables['v1']\n",
    "        )\n",
    "    \n",
    "    if initial_state is not None:\n",
    "        init_state = initial_state\n",
    "    else:\n",
    "        groud_2q_3levels = Statevector([1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        init_state = groud_2q_3levels\n",
    "\n",
    "    ansatz_res = hamiltonian_solver.solve(t_span=[0., pulses.duration*dt],\n",
    "                                          y0=init_state, atol=1e-8, rtol=1e-8)\n",
    "    return ansatz_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d686095",
   "metadata": {},
   "source": [
    "### Calculate eigen-energy given measurement in the Molecule pauli bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8c07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define relevant functions\n",
    "def expval_with_variance(counts,\n",
    "                         operator_coeff: int,\n",
    "                         diagonal: Optional[np.ndarray] = None,\n",
    "                        finite_sampling=True) -> Tuple[float, float]:\n",
    "    r\"\"\"Compute the expectation value of a diagonal operator from counts.\n",
    "\n",
    "    Args:\n",
    "        counts: counts object.\n",
    "        diagonal: Optional, values of the diagonal observable. If None the\n",
    "                  observable is set to :math:`Z^\\otimes n`.\n",
    "\n",
    "    Returns:\n",
    "        (float, float): the expectation value and variance.\n",
    "    \"\"\"\n",
    "    if finite_sampling:\n",
    "        # Get counts shots and probabilities\n",
    "        probs = np.array(list(counts.values()))\n",
    "        shots = probs.sum()\n",
    "        probs = probs / shots\n",
    "        \n",
    "        # Get diagonal operator coefficients\n",
    "        if diagonal is None:\n",
    "            coeffs = np.array([(-1) ** (key.count('1') % 2)\n",
    "                               for key in counts.keys()])\n",
    "        else:\n",
    "            keys = [int(key, 2) for key in counts.keys()]\n",
    "            coeffs = np.asarray(diagonal[keys])\n",
    "            \n",
    "        # Compute expval\n",
    "        expval = coeffs.dot(probs)\n",
    "        \n",
    "        # Compute variance\n",
    "        if diagonal is None:\n",
    "            # The square of the parity diagonal is the all 1 vector\n",
    "            sq_expval = np.sum(probs)\n",
    "        else:\n",
    "            sq_expval = (coeffs ** 2).dot(probs)\n",
    "        variance = (sq_expval - expval ** 2) / shots\n",
    "    else:\n",
    "        probs = counts\n",
    "\n",
    "        # Get diagonal operator coefficients\n",
    "        if diagonal is None:\n",
    "            coeffs = np.array([(-1) ** (key.count('1') % 2)\n",
    "                               for key in probs.keys()])\n",
    "        else:\n",
    "            keys = [int(key, 2) for key in probs.keys()]\n",
    "            coeffs = np.asarray(diagonal[keys])\n",
    "\n",
    "        # Compute expval\n",
    "        expval = coeffs.dot(list(probs.values()))\n",
    "\n",
    "        # Compute variance\n",
    "        if diagonal is None:\n",
    "            # The square of the parity diagonal is the all 1 vector\n",
    "            sq_expval = np.sum(list(probs.values()))\n",
    "        else:\n",
    "            sq_expval = (coeffs ** 2).dot(list(probs.values()))\n",
    "        variance = (sq_expval - expval ** 2)# / shots\n",
    "\n",
    "    # Compute standard deviation\n",
    "    if variance < 0:\n",
    "        if not np.isclose(variance, 0):\n",
    "            logger.warning(\n",
    "                'Encountered a negative variance in expectation value calculation.'\n",
    "                '(%f). Setting standard deviation of result to 0.', variance)\n",
    "        variance = 0.0\n",
    "    return expval * operator_coeff, variance * abs(operator_coeff) ** 2\n",
    "\n",
    "def calculate_accumulate_exp_val(probs, coeffs, finite_sampling):\n",
    "    combined_expval = 0.0\n",
    "    combined_variance = 0.0\n",
    "    if type(probs) != list:\n",
    "        probs = [probs]\n",
    "    for ind, result in enumerate(probs):\n",
    "        exp_val, exp_var = expval_with_variance(result, coeffs[ind], finite_sampling=finite_sampling)\n",
    "        # Accumulate\n",
    "        combined_expval += exp_val\n",
    "        combined_variance += exp_var\n",
    "    combined_stddev = np.sqrt(combined_variance)\n",
    "    return combined_expval, combined_stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb04f6",
   "metadata": {},
   "source": [
    "### Measure the simulation result in all the given pauli bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15496e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.result import marginal_counts\n",
    "hadamard = (1 / np.sqrt(2)) * np.array([[1,1],[1,-1]])\n",
    "s_dg = np.array([[1,0],[0,1j]])\n",
    "identity = np.array([[1,0],[0,1]])\n",
    "\n",
    "def finite_sampling_measure(state, paulis, coeffs, leakage=False, shots=10000):\n",
    "    ansatz_density_matrix = qiskit.quantum_info.DensityMatrix(state)\n",
    "    if leakage:\n",
    "        # filter out leakage\n",
    "        reduced_density_matrix = qiskit.quantum_info.DensityMatrix(\n",
    "            [list(ansatz_density_matrix.data[0][0:2]) + list(ansatz_density_matrix.data[0][3:5]),\n",
    "             list(ansatz_density_matrix.data[1][0:2]) + list(ansatz_density_matrix.data[1][3:5]),\n",
    "             list(ansatz_density_matrix.data[3][0:2]) + list(ansatz_density_matrix.data[3][3:5]),\n",
    "             list(ansatz_density_matrix.data[4][0:2]) + list(ansatz_density_matrix.data[4][3:5])])\n",
    "        leakage_prob = 1 - sum(reduced_density_matrix.probabilities())\n",
    "        print(\"leakage percent: \" + str(leakage_prob*100) + \"%\")\n",
    "        ansatz_density_matrix = reduced_density_matrix / reduced_density_matrix.trace()\n",
    "\n",
    "    # apply rotations to the result state\n",
    "    results = [] \n",
    "    for pauli in paulis:\n",
    "        measure_op = 1\n",
    "        marginal_qubits = None\n",
    "        for i, val in enumerate(reversed(pauli)):\n",
    "            if val == 'Y':\n",
    "                cur_measure_op = hadamard @ s_dg\n",
    "                measure_op = np.kron(cur_measure_op, measure_op)\n",
    "            if val == 'X':\n",
    "                cur_measure_op = hadamard\n",
    "                measure_op = np.kron(cur_measure_op, measure_op)\n",
    "            if val == 'Z':\n",
    "                cur_measure_op = identity\n",
    "                measure_op = np.kron(cur_measure_op, measure_op)\n",
    "            if val == 'I': # we calculate expectation value, so we do not need to measure the identity\n",
    "                cur_measure_op = identity\n",
    "                measure_op = np.kron(cur_measure_op, measure_op)\n",
    "                marginal_qubits = 1 - i\n",
    "\n",
    "        measured_density_matrix = ansatz_density_matrix.evolve(measure_op)\n",
    "\n",
    "        if shots is not None:\n",
    "            counts = measured_density_matrix.sample_counts(shots)\n",
    "            if marginal_qubits is not None:\n",
    "                counts = marginal_counts(counts, [marginal_qubits])\n",
    "            results.append(counts)\n",
    "            finite_sampling = True\n",
    "        else:\n",
    "            probs = measured_density_matrix.probabilities_dict()\n",
    "            if marginal_qubits is not None:\n",
    "                probs = marginal_counts(probs, [marginal_qubits])\n",
    "            results.append(probs)\n",
    "            finite_sampling=False\n",
    "    \n",
    "    expval, stddev = calculate_accumulate_exp_val(results, coeffs, finite_sampling)\n",
    "    return expval, stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c280aa",
   "metadata": {},
   "source": [
    "### the loss function - gets all the parameters and return the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014bc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_energy(theta, paulis, coeffs, system_model, backend, dt=0.222, decoherence=False, shots=None):\n",
    "    init_sched = create_ansatz(theta, dt, backend)\n",
    "        \n",
    "    print(theta)\n",
    "    ansatz_result = run_ansatz(system_model, init_sched, dt, decoherence=decoherence)\n",
    "    expval, stddev = finite_sampling_measure(ansatz_result.y[-1], paulis[1:], coeffs[1:], leakage=True, shots=shots)\n",
    "    print(\"energy: \" + str(expval + coeffs[0]))\n",
    "    # in case I will want to return also the varience and the counts\n",
    "    # return results, expval, stddev\n",
    "    \n",
    "    # save in global variables the mid-optimization values\n",
    "    thetas.append(copy.deepcopy(theta))\n",
    "    values.append(expval)\n",
    "    states.append(ansatz_result.y[-1])\n",
    "    return expval.real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23f037",
   "metadata": {},
   "source": [
    "a function that already have the static parameters hard-coded for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "477a3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy(theta):\n",
    "    paulis = all_paulis[-1]\n",
    "    coeffs = all_coeffs[-1]\n",
    "    system_model = manila_model_3levels\n",
    "    dt = 0.222\n",
    "    shots = 10000\n",
    "    decoherence = True\n",
    "    backend = backend_manila\n",
    "    energy = evaluate_energy(theta, paulis, coeffs, system_model, backend, dt, decoherence, shots)\n",
    "    return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb85f49",
   "metadata": {},
   "source": [
    "# Define the ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f15e3",
   "metadata": {},
   "source": [
    "### First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d807f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_fun(pulse_duration, max_amp):\n",
    "    return np.sign(pulse_duration) * min(abs(pulse_duration) / 20, max_amp)\n",
    "\n",
    "def create_ansatz_old_function(theta, dt):\n",
    "    \"\"\"\n",
    "    theta - durationa of drivea in ns\n",
    "    CR pulses - triple weight\n",
    "    \"\"\"\n",
    "    control_weight = 5\n",
    "    \n",
    "    drag0_1_dur = 54\n",
    "    drag1_1_dur = 0\n",
    "    control1_dur = int(control_weight * theta[0] / dt\n",
    "\n",
    "    drag0_2_dur = int(theta[1] / dt)\n",
    "    drag1_2_dur = int(theta[2] / dt)\n",
    "    # z rotations\n",
    "    z0_1 = theta[3] / 10 # 1/10 weight\n",
    "    z1_1 = theta[4] / 10 # 1/10 weight\n",
    "    \n",
    "    \n",
    "    x_sigma = 64\n",
    "    x_beta = -1.4\n",
    "    x_amp = 0.2\n",
    "    control_amp = 0.8\n",
    "    control_width = abs(control1_dur)-14\n",
    "    if control_width < 0:\n",
    "        control_width = abs(control1_dur)\n",
    "    \n",
    "    with pulse.build() as ansatz_sol_sched:\n",
    "        if drag0_1_dur != 0:\n",
    "            pulse.play(pulse.Drag(abs(drag0_1_dur), amp_fun(drag0_1_dur, x_amp), x_sigma, x_beta),\n",
    "                       pulse.DriveChannel(0))\n",
    "        if drag1_1_dur != 0:\n",
    "            pulse.play(pulse.Drag(abs(drag1_1_dur), amp_fun(drag1_1_dur, x_amp), x_sigma, x_beta),\n",
    "                       pulse.DriveChannel(1))\n",
    "        if drag0_1_dur != 0 or drag1_1_dur != 0:\n",
    "            delay_1 = abs(drag1_1_dur)\n",
    "            if abs(drag0_1_dur) > abs(drag1_1_dur):\n",
    "                delay_1 = abs(drag0_1_dur)\n",
    "            else:\n",
    "                delay_1 = abs(drag1_1_dur)\n",
    "            pulse.delay(delay_1, pulse.ControlChannel(0))\n",
    "        else:\n",
    "            delay_1 = 0\n",
    "        pulse.play(pulse.GaussianSquare(duration=abs(control1_dur), amp=amp_fun(control1_dur, control_amp), sigma=64,\n",
    "                                        width=control_width), pulse.ControlChannel(0))\n",
    "        if drag0_2_dur != 0:\n",
    "            pulse.delay(delay_1 - abs(drag0_1_dur) + abs(control1_dur), pulse.DriveChannel(0))\n",
    "            pulse.shift_phase(z0_1, pulse.DriveChannel(0))\n",
    "            pulse.play(pulse.Drag(abs(drag0_2_dur), amp_fun(drag0_2_dur, x_amp), x_sigma, x_beta), \n",
    "                       pulse.DriveChannel(0))\n",
    "        if drag1_2_dur != 0:\n",
    "            pulse.delay(delay_1 - abs(drag1_1_dur) + abs(control1_dur), pulse.DriveChannel(1))\n",
    "            pulse.shift_phase(z1_1, pulse.DriveChannel(1))\n",
    "            pulse.play(pulse.Drag(abs(drag1_2_dur), amp_fun(drag1_2_dur, x_amp), x_sigma, x_beta),\n",
    "                       pulse.DriveChannel(1))\n",
    "    return ansatz_sol_sched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c2e12",
   "metadata": {},
   "source": [
    "### Generalize to multiple layers and account for echo in CR and hardware constrains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8383b",
   "metadata": {},
   "source": [
    "In real hardware each wavefunction must be a multiple of 16, and there is a minimum length for pulses. if the pulse is very short, replace the gaussian envelope of the single qubit pulses also to gaussian-squre, in order to avoid real hardware errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb638ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pansatz_layer(two_qubit_durations, two_qubit_width, single_qubit_durations, \n",
    "                         x_amp, x_sigma, x_beta, control_amp, first_layer=False):\n",
    "    single_qubit_drives = []\n",
    "    two_qubit_drives = []\n",
    "    two_qubit_tag_drives = []\n",
    "    \n",
    "    # two qubit pulses\n",
    "    if not first_layer:\n",
    "        for cur_dur, cur_width in zip(two_qubit_durations, two_qubit_width):\n",
    "            if cur_dur != 0:\n",
    "                two_qubit_drive = list(qiskit.pulse.library.gaussian_square(duration=abs(int(cur_dur/2)), \n",
    "                                                              amp=amp_fun(cur_dur/2, control_amp), sigma=64,\n",
    "                                                              width=cur_width/2).samples)\n",
    "                two_qubit_drive, _ = add_padding(two_qubit_drive)\n",
    "                two_qubit_drives.append(two_qubit_drive)\n",
    "\n",
    "                two_qubit_tag_drive = list(qiskit.pulse.library.gaussian_square(duration=abs(int(cur_dur/2)), \n",
    "                                                              amp=-1*amp_fun(cur_dur/2, control_amp), sigma=64,\n",
    "                                                              width=cur_width/2).samples)\n",
    "                two_qubit_tag_drive, _ = add_padding(two_qubit_tag_drive)\n",
    "                two_qubit_tag_drives.append(two_qubit_tag_drive)\n",
    "            else:\n",
    "                two_qubit_drives.append([])\n",
    "                two_qubit_tag_drives.append([])\n",
    "    \n",
    "    # single qubit pulses\n",
    "    for cur_dur in single_qubit_durations:\n",
    "        if cur_dur != 0:\n",
    "            if abs(cur_dur) > 32:\n",
    "                single_qubit_drive = list(qiskit.pulse.library.drag(abs(cur_dur), amp_fun(cur_dur, x_amp),\n",
    "                                                 x_sigma, x_beta).samples)\n",
    "                single_qubit_drive, _ = add_padding(single_qubit_drive)\n",
    "                single_qubit_drives.append(single_qubit_drive)\n",
    "            else:\n",
    "                temp_width = abs(cur_dur) - 14\n",
    "                if temp_width < 0:\n",
    "                    temp_width = abs(cur_dur)\n",
    "                single_qubit_drive = list(qiskit.pulse.library.gaussian_square(duration=abs(cur_dur), \n",
    "                                                                     amp=amp_fun(cur_dur, x_amp),\n",
    "                                                                     sigma=x_sigma, \n",
    "                                                                     width=temp_width).samples)\n",
    "                single_qubit_drive, _ = add_padding(single_qubit_drive)\n",
    "                single_qubit_drives.append(single_qubit_drive)\n",
    "        else:\n",
    "            single_qubit_drives.append([])\n",
    "\n",
    "    return two_qubit_drives, two_qubit_tag_drives, single_qubit_drives\n",
    "\n",
    "def create_durations_and_widths(theta, dt, num_of_qubits, num_of_layers, initial_layer_param=[54, 0, 54, 0],\n",
    "                                control_weight = 2.5, z_rotation_weight = 1/10):\n",
    "    \n",
    "    layers_durations = []\n",
    "    layers_widths = []\n",
    "    \n",
    "    layers_durations.append({\"single_qubit\": initial_layer_param}) # layer 0\n",
    "    layers_widths.append([]) # layer 0\n",
    "    \n",
    "    parameter_counter = 0\n",
    "    for layer in range(num_of_layers):\n",
    "        # two qubit pulses\n",
    "        two_qubit_dur = []\n",
    "        layer_width = []\n",
    "        for channel in range(num_of_qubits-1):\n",
    "            control_dur = int(control_weight * theta[parameter_counter] / dt)\n",
    "            two_qubit_dur.append(control_dur)\n",
    "            parameter_counter += 1\n",
    "            # width calculation\n",
    "            control_width = abs(control_dur)-14\n",
    "            if control_width < 0:\n",
    "                control_width = abs(control_dur)\n",
    "            layer_width.append(control_width)\n",
    "        layer_durations = {\"two_qubit\": two_qubit_dur}\n",
    "        layers_widths.append(layer_width)\n",
    "        \n",
    "        # single qubit pulses\n",
    "        single_qubit_dur = []\n",
    "        for channel in range(num_of_qubits):\n",
    "            single_qubit_dur.append(int(theta[parameter_counter] / dt))\n",
    "            parameter_counter += 1\n",
    "        layer_durations[\"single_qubit\"] = single_qubit_dur\n",
    "        single_qubit_phase_rotation = []\n",
    "        for channel in range(num_of_qubits):\n",
    "            single_qubit_phase_rotation.append(theta[parameter_counter] * z_rotation_weight)\n",
    "            parameter_counter += 1\n",
    "        layer_durations[\"single_qubit_phase\"] = single_qubit_phase_rotation\n",
    "        \n",
    "        layers_durations.append(layer_durations)\n",
    "    \n",
    "    return layers_durations, layers_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_fun(pulse_duration, max_amp):\n",
    "    return np.sign(pulse_duration) * min(abs(pulse_duration) / 20, max_amp)\n",
    "\n",
    "def add_padding(waveform_samples, before=False):\n",
    "    if len(waveform_samples) == 0:\n",
    "        return waveform_samples, 0\n",
    "    padding_to_add = 16 - (len(waveform_samples) % 16)\n",
    "    if before:\n",
    "        new_samples = [0.] * padding_to_add + waveform_samples\n",
    "    else:\n",
    "        new_samples = waveform_samples + [0.] * padding_to_add\n",
    "    if len(new_samples) < 64:\n",
    "        if before:\n",
    "            new_samples = [0.] * (64 - len(new_samples)) + new_samples\n",
    "        else:\n",
    "            new_samples = new_samples + [0.] * (64 - len(new_samples))\n",
    "    return new_samples, len(new_samples) - len(waveform_samples)\n",
    "\n",
    "def create_ansatz(theta, dt, backend, layers=1, qubits=[0,1]):\n",
    "    \"\"\"\n",
    "    theta - durations of drives in ns\n",
    "    \"\"\"\n",
    "    control_weight = 2.5\n",
    "    z_rotation_weight = 1/10\n",
    "    flip_duration = 54\n",
    "    \n",
    "    backend_channels = backend.configuration().to_dict()['channels']\n",
    "    for channel in backend_channels:\n",
    "        if backend_channels[channel]['operates']['qubits'] == [qubits[0], qubits[1]]:\n",
    "            control_channel_0 = int(channel.split('u')[1])\n",
    "    control_channels = [control_channel_0]\n",
    "    \n",
    "    \n",
    "    x_sigma = 64\n",
    "    x_beta = -1.4\n",
    "    x_amp = 0.2\n",
    "    control_amp = 0.8\n",
    "    \n",
    "    layers_durations, layers_widths = create_durations_and_widths(theta, dt, len(qubits), layers, \n",
    "                                                                  [54, 0], # initial layer params\n",
    "                                                                  control_weight, z_rotation_weight)\n",
    "    \n",
    "    single_qubit_drives = []\n",
    "    two_qubit_drives = []\n",
    "    two_qubit_tag_drives = []\n",
    "    single_qubit_delays = []\n",
    "    \n",
    "    single_channels_times = {}\n",
    "    for qubit in qubits:\n",
    "        single_channels_times[qubit] = 0\n",
    "    control_channels_times = [0] * len(control_channels)\n",
    "    current_time = 0\n",
    "    \n",
    "    with pulse.build() as ansatz_sol_sched:        \n",
    "        ###################\n",
    "        ##### Layer 0 #####\n",
    "        ###################\n",
    "        # initial 1 qubit pulses\n",
    "        _, _, single_qubit_drives_0 = \\\n",
    "            create_pansatz_layer([],\n",
    "                                 [],\n",
    "                                 layers_durations[0][\"single_qubit\"], \n",
    "                                 x_amp, x_sigma, x_beta, control_amp, first_layer=True)\n",
    "        \n",
    "        ########################\n",
    "        ##### Other Layers #####\n",
    "        ########################\n",
    "        two_qubit_drives = []\n",
    "        two_qubit_tag_drives = []\n",
    "        single_qubit_drives = []\n",
    "\n",
    "        for layer in range(1, layers+1):\n",
    "            temp_two_qubit_drives, temp_two_qubit_tag_drives, temp_single_qubit_drives = \\\n",
    "                create_pansatz_layer(layers_durations[layer][\"two_qubit\"],\n",
    "                                     layers_widths[layer],\n",
    "                                     layers_durations[layer][\"single_qubit\"],\n",
    "                                     x_amp, x_sigma, x_beta, control_amp)\n",
    "            two_qubit_drives.append(temp_two_qubit_drives)\n",
    "            two_qubit_tag_drives.append(temp_two_qubit_tag_drives)\n",
    "            single_qubit_drives.append(temp_single_qubit_drives)\n",
    "            \n",
    "        #######################\n",
    "        ##### Flip Pulses #####\n",
    "        #######################\n",
    "        flip_plus = list(qiskit.pulse.library.drag(flip_duration, 2*amp_fun(flip_duration, x_amp),\n",
    "                                                 x_sigma, x_beta).samples)\n",
    "        flip_minus = list(qiskit.pulse.library.drag(flip_duration, -2*amp_fun(flip_duration, x_amp),\n",
    "                                                 x_sigma, x_beta).samples)\n",
    "        \n",
    "        #################################\n",
    "        ##### Creating the schedule #####\n",
    "        #################################\n",
    "        \n",
    "        # add padding to flip pulses\n",
    "        flip_plus, _ = add_padding(flip_plus)\n",
    "        flip_minus, _ = add_padding(flip_minus)\n",
    "        # initial layer\n",
    "        for qubit_num in range(len(qubits)):\n",
    "            pulse.play(pulse.Waveform(single_qubit_drives_0[qubit_num]), pulse.DriveChannel(qubits[qubit_num]))\n",
    "            single_channels_times[qubits[qubit_num]] += len(single_qubit_drives_0[qubit_num])\n",
    "        current_time = max(single_channels_times.values())\n",
    "        # the rest of the layers\n",
    "        for layer_num, (two_qubit_drive, two_qubit_tag_drive, single_qubit_drive) in\\\n",
    "            enumerate(zip(two_qubit_drives, two_qubit_tag_drives, single_qubit_drives)):\n",
    "            # two qubit pulses\n",
    "            # first do layer with control in even numbered qubits and than the alternating layer with\n",
    "            # control in the odd numbered qubits\n",
    "            for alternating_index in [0, 1]:\n",
    "                for control_index in range(alternating_index, len(two_qubit_drive), 2):\n",
    "                    if len(two_qubit_drive[control_index]) > 0:\n",
    "                        temp_time = current_time\n",
    "                        \n",
    "                        pulse.delay(temp_time - control_channels_times[control_index],\n",
    "                                    pulse.ControlChannel(control_channels[control_index]))\n",
    "                        control_channels_times[control_index] += temp_time\n",
    "                        pulse.play(pulse.Waveform(two_qubit_drive[control_index]), \n",
    "                                   pulse.ControlChannel(control_channels[control_index]))\n",
    "                        temp_time += len(two_qubit_drive[control_index])\n",
    "                        control_channels_times[control_index] = temp_time\n",
    "                        # flip pulse\n",
    "                        pulse.delay(temp_time - single_channels_times[qubits[control_index]], \n",
    "                                    pulse.DriveChannel(qubits[control_index]))\n",
    "                        pulse.play(pulse.Waveform(flip_plus), pulse.DriveChannel(qubits[control_index]))\n",
    "                        temp_time += len(flip_plus)\n",
    "                        single_channels_times[qubits[control_index]] = temp_time\n",
    "                        # echoed part\n",
    "                        pulse.delay(temp_time - control_channels_times[control_index], \n",
    "                                    pulse.ControlChannel(control_channels[control_index]))\n",
    "                        pulse.play(pulse.Waveform(two_qubit_tag_drive[control_index]), \n",
    "                                   pulse.ControlChannel(control_channels[control_index]))\n",
    "                        temp_time += len(two_qubit_tag_drive[control_index])\n",
    "                        control_channels_times[control_index] = temp_time\n",
    "                        # unflip pulse\n",
    "                        pulse.delay(temp_time - single_channels_times[qubits[control_index]],\n",
    "                                    pulse.DriveChannel(qubits[control_index]))\n",
    "                        pulse.play(pulse.Waveform(flip_minus), pulse.DriveChannel(qubits[control_index]))\n",
    "                        temp_time += len(flip_minus)\n",
    "                        single_channels_times[qubits[control_index]] = temp_time\n",
    "                current_time = max(single_channels_times.values())\n",
    "\n",
    "            # single qubit pulses   \n",
    "            for qubit_num in range(len(qubits)):\n",
    "                pulse.delay(current_time - single_channels_times[qubits[qubit_num]],\n",
    "                                pulse.DriveChannel(qubits[qubit_num]))\n",
    "                # layers start from 1\n",
    "                pulse.shift_phase(layers_durations[layer_num+1][\"single_qubit_phase\"][qubit_num],\n",
    "                                  pulse.DriveChannel(qubits[qubit_num]))\n",
    "                pulse.play(pulse.Waveform(single_qubit_drive[qubit_num]), pulse.DriveChannel(qubits[qubit_num]))\n",
    "                single_channels_times[qubits[qubit_num]] += (current_time - \\\n",
    "                                                                 single_channels_times[qubits[qubit_num]] +\\\n",
    "                                                                 len(single_qubit_drive[qubit_num]))\n",
    "            current_time = max(single_channels_times.values())\n",
    "                \n",
    "    return ansatz_sol_sched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b7e001",
   "metadata": {},
   "source": [
    "# Functions to build the problem parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4668ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qubit_op(dist, mapper=\"parity\"):\n",
    "    molecule = Molecule(geometry=[[\"He\", [0.0, 0.0, 0.0]], [\"H\", [0.0, 0.0, dist]]], charge=1, multiplicity=1)\n",
    "    driver = ElectronicStructureMoleculeDriver(\n",
    "        molecule, basis=\"sto3g\", driver_type=ElectronicStructureDriverType.PYSCF)\n",
    "    es_problem = ElectronicStructureProblem(driver)\n",
    "    second_q_op = es_problem.second_q_ops()\n",
    "    if mapper == \"parity\":\n",
    "        qubit_converter = QubitConverter(mapper=ParityMapper(), two_qubit_reduction=True)\n",
    "    elif mapper == \"jordan\":\n",
    "        qubit_converter = QubitConverter(mapper=JordanWignerMapper(), two_qubit_reduction=True)\n",
    "    elif mapper == \"bravi\":\n",
    "        qubit_converter = QubitConverter(mapper=BravyiKitaevMapper(), two_qubit_reduction=True)\n",
    "    else:\n",
    "        print(\"mapper should be one of parity, jordan or bravi\")\n",
    "        return None\n",
    "    qubit_op = qubit_converter.convert(second_q_op[0], num_particles=es_problem.num_particles)\n",
    "    return qubit_op, es_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e31f875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hf_energy(dist):\n",
    "    temp_mol = gto.M(atom = 'H 0 0 0; H 0 0 ' + str(dist), basis = 'sto3g')\n",
    "    temp_hf = scf.HF(temp_mol)\n",
    "    return temp_hf.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891e13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accurate_state(dist):\n",
    "    temp_qubit_op = get_qubit_op(dist)[0]\n",
    "    eigen_values, eigen_vectors = np.linalg.eigh(temp_qubit_op.to_matrix())\n",
    "    min_eigen_value = eigen_values[0]\n",
    "    min_eigen_vector = eigen_vectors.transpose()[0]\n",
    "    return min_eigen_value, min_eigen_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff3e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exact_energies(dist):\n",
    "    numpy_solver = NumPyMinimumEigensolver()\n",
    "    qubit_converter = QubitConverter(mapper=ParityMapper(), two_qubit_reduction=True)\n",
    "    calc = GroundStateEigensolver(qubit_converter, numpy_solver)\n",
    "    _, es_prob = get_qubit_op(dist)\n",
    "    temp_res = calc.solve(es_prob)\n",
    "    return temp_res, temp_res.total_energies[0], temp_res.nuclear_repulsion_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bef352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paulis_and_coeffs(dist):\n",
    "    qubit_op = get_qubit_op(dist)[0]\n",
    "    paulis = []\n",
    "    for op in qubit_op:\n",
    "        paulis.append(str(op)[-op.num_qubits:])\n",
    "    return paulis, qubit_op.coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53763eac",
   "metadata": {},
   "source": [
    "# Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1bdbed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energies(energies, exp_energies, distances):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(distances, energies, lw=3, label=\"Exact Energy\")\n",
    "    plt.plot(distances, exp_energies, lw=3, label=\"Exp Energy\")\n",
    "    plt.fill_between(distances, np.array(energies)-0.0016, np.array(energies)+0.0016, \n",
    "                     alpha=0.2, facecolor='#089FFF', label=\"Chemical accuracy\")\n",
    "    plt.xlabel('Atomic distance (Angstrom)')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df24a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energies_error(energies, exp_energies, distances):\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(distances, np.abs(np.array(energies) - np.array(exp_energies)), lw=3, label=\"Exp Error\")\n",
    "    plt.axhline(0.0016, linestyle='--', label=\"Chemical accuracy\")\n",
    "    plt.xlabel('Atomic distance (Angstrom)')\n",
    "    plt.ylabel('Energy Error')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfed82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(values_hist_arr, dist):\n",
    "    values_hist_arr_real = np.array(values_hist_arr[dist])\n",
    "    paulis, coeffs = get_paulis_and_coeffs(dist)\n",
    "    values_hist_arr_real = values_hist_arr_real + coeffs[0]\n",
    "    values_hist_arr_real = np.array([spsa_value.real for spsa_value in values_hist_arr_real])\n",
    "    \n",
    "    temp_res, min_energy, nuclear_repulsion_energy = get_exact_energies(dist)\n",
    "    min_eigenvalue = min_energy - nuclear_repulsion_energy\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(list(range(len(values_hist_arr[dist]))), values_hist_arr_real , lw=3, label=\"energy\")\n",
    "    plt.plot(list(range(len(values_hist_arr[dist]))), [min_eigenvalue] * len(values_hist_arr_real) , 'k', lw=3, \n",
    "             label=\"optimal energy\", linestyle=\"dashed\")\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"Energy\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.title(\"H_2 SPSA convergence\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bafb8b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_populations_2q_leak(sol_vec, time):\n",
    "    popu = [psi.probabilities() for psi in sol_vec]\n",
    "    popu = np.array(popu).transpose()\n",
    "    leakage = popu[2] + popu[5] + popu[6] + popu[7] + popu[8]\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    plt.plot(time, popu[0], lw=3, label=\"Population in |00>\")\n",
    "    plt.plot(time, popu[1], lw=3, label=\"Population in |01>\")\n",
    "#     plt.plot(time, popu[2], lw=3, label=\"Population in |02>\")\n",
    "    plt.plot(time, popu[3], lw=3, label=\"Population in |10>\")\n",
    "    plt.plot(time, popu[4], lw=3, label=\"Population in |11>\")\n",
    "    plt.plot(time, leakage, lw=3, label=\"leakage\")\n",
    "#     plt.plot(time, popu[5], lw=3, label=\"Population in |12>\")\n",
    "#     plt.plot(time, popu[6], lw=3, label=\"Population in |20>\")\n",
    "#     plt.plot(time, popu[7], lw=3, label=\"Population in |21>\")\n",
    "#     plt.plot(time, popu[8], lw=3, label=\"Population in |22>\")\n",
    "    plt.xlabel(\"Time (ns)\")\n",
    "    plt.ylabel(\"Population\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.ylim([0, 1.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e39a9",
   "metadata": {},
   "source": [
    "# Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9598a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.algorithms.optimizers import SPSA\n",
    "\n",
    "dists = [0.3, 0.5, 0.7, 0.8, 1, 1.5, 2, 3]\n",
    "\n",
    "thetas_hist = {}\n",
    "values_hist = {}\n",
    "states_hist = {}\n",
    "all_paulis = []\n",
    "all_coeffs =[]\n",
    "\n",
    "for dist in dists:\n",
    "    print(\"#########################################\")\n",
    "    print(\"Solving for distance \" + str(dist) + \":\")\n",
    "    print(\"#########################################\")\n",
    "    paulis, coeffs = get_paulis_and_coeffs(dist)\n",
    "    all_paulis.append(paulis)\n",
    "    all_coeffs.append(coeffs)\n",
    "    temp_res, min_energy, nuclear_repulsion_energy = get_exact_energies(dist)\n",
    "    target_energy = min_energy - nuclear_repulsion_energy\n",
    "\n",
    "    initial_theta = [0, 54 * dt, 0, 0, 0]\n",
    "\n",
    "    learning_rate1 = [3, 2, 2, 1, 1, 1]\n",
    "    learning_rate2 = [0.5] * 5\n",
    "    learning_rate3 = [0.2] * 5\n",
    "    learning_rate4 = [0.1] * 5\n",
    "    learning_rate5 = [0.05] * 70\n",
    "    learning_rate = learning_rate1 + learning_rate2 + learning_rate3 + learning_rate4 + learning_rate5\n",
    "\n",
    "    perturbation1 = [3*dt, 3*dt, 3*dt, 3*dt]\n",
    "    perturbation2 = [2*dt] * 5\n",
    "    perturbation3 = [1*dt] * 70\n",
    "    perturbation = perturbation1 + perturbation2 + perturbation3\n",
    "\n",
    "    thetas = []\n",
    "    values = []\n",
    "    states = []\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    spsa = SPSA(maxiter=70, learning_rate=learning_rate, perturbation=perturbation)\n",
    "    vqe_result = spsa.minimize(calculate_energy, initial_theta)\n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    thetas_hist[dist] = copy.deepcopy(thetas)\n",
    "    values_hist[dist] = copy.deepcopy(values)\n",
    "    states_hist[dist] = copy.deepcopy(states)\n",
    "\n",
    "    opt_theta_index = values.index(np.min(values))\n",
    "\n",
    "    print(f\"Finished the VQE in {toc - tic:0.4f} seconds\")\n",
    "    print(\"final theta: \" + str(thetas[opt_theta_index]))\n",
    "    res = min(values).real + coeffs[0]\n",
    "    print(\"min eigen_value found: \" + str(res))\n",
    "    print(\"absolute error: \" + str(np.abs(res - target_energy)))\n",
    "    print(\"number of function evaluations: \" + str(vqe_result.nfev))\n",
    "    opt_sched = create_ansatz(thetas[opt_theta_index], dt, backend_manila)\n",
    "    print(\"solution schedule duration: \" + str(opt_sched.duration * dt) + \" [ns]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b757831",
   "metadata": {},
   "source": [
    "### Test steepest hill climbing optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6bb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [0.3, 0.5, 0.7, 0.8, 1, 1.5, 2, 3]\n",
    "\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "all_paulis = []\n",
    "all_coeffs = []\n",
    "all_nuclear_repulsion_energies = []\n",
    "\n",
    "backend = backend_manila\n",
    "system_model = manila_model_3levels\n",
    "qubits = [0,1]\n",
    "shots = 10000\n",
    "dt = 0.222\n",
    "decoherence = True\n",
    "layers = 1\n",
    "\n",
    "for dist in dists:\n",
    "    print(\"#########################################\")\n",
    "    print(\"Solving for distance \" + str(dist) + \":\")\n",
    "    print(\"#########################################\")\n",
    "    paulis, coeffs = get_paulis_and_coeffs(dist)\n",
    "    all_paulis.append(paulis)\n",
    "    all_coeffs.append(coeffs)\n",
    "    temp_res, min_energy, nuclear_repulsion_energy = get_exact_energies(dist)\n",
    "    all_nuclear_repulsion_energies.append(nuclear_repulsion_energy)\n",
    "    target_energy = min_energy\n",
    "\n",
    "    initial_theta = [0, 54 * dt, 0, 0, 0]\n",
    "    \n",
    "    parameter_search_space = {\n",
    "        \"0\": np.linspace(20, -20, 21),\n",
    "        \"1\": np.linspace(30, -30, 21),\n",
    "        \"2\": np.linspace(30, -30, 21),\n",
    "        \"3\": np.linspace(4, -4, 17),\n",
    "        \"4\": np.linspace(4, -4, 17)\n",
    "    }   \n",
    "    \n",
    "    parameters_order = [0, 1, 2, 3, 4]\n",
    "\n",
    "    cur_dist_res_dict = {\"all_runs\": {\"values\": [], \"thetas\": [], \"stddev\": [], \"states\": []},\n",
    "                         \"steps\": {\"min_energies\": [], \"min_std\": [], \"thetas\": {}}\n",
    "                        }\n",
    "    results_dict[dist] = cur_dist_res_dict\n",
    "\n",
    "    cur_theta = copy.deepcopy(initial_theta)\n",
    "    cur_energy = 10\n",
    "    cur_stddev = 0\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    for i in range(4):\n",
    "        if i >= 2:\n",
    "            parameter_search_space = {\n",
    "                \"0\": np.linspace(5, -5, 11),\n",
    "                \"1\": np.linspace(5, -5, 11),\n",
    "                \"2\": np.linspace(5, -5, 11),\n",
    "                \"3\": np.linspace(0.5, -0.5, 11),\n",
    "                \"4\": np.linspace(0.5, -0.5, 11)\n",
    "            }\n",
    "        for param_index in parameters_order:\n",
    "            print(\"theta: \" + str(cur_theta))\n",
    "            print(\"working on theta[\" + str(param_index) + \"]\")\n",
    "            cur_step_circuits = create_optimization_step_circuits(cur_theta, param_index, \n",
    "                                                                  parameter_search_space[str(param_index)], \n",
    "                                                                  backend, qubits, \n",
    "                                                                  cur_dist_res_dict[\"all_runs\"], layers=layers, dt=dt)\n",
    "            \n",
    "            step_min_energy, cur_step_energies = evaluate_energy_simulation_multiple_circuits(cur_step_circuits, \n",
    "                                                            paulis, coeffs, system_model, \n",
    "                                                            nuclear_repulsion_energy, cur_dist_res_dict[\"all_runs\"], \n",
    "                                                            dt=dt, decoherence=decoherence, shots=shots)\n",
    "            print(\"min energy found: \" + str(step_min_energy))\n",
    "            cur_dist_res_dict[\"steps\"][\"min_energies\"].append(step_min_energy)\n",
    "            opt_energy_index = cur_step_energies.index(step_min_energy)\n",
    "            cur_step_std = cur_dist_res_dict[\"all_runs\"][\"stddev\"][-len(cur_dist_res_dict):]\n",
    "            cur_dist_res_dict[\"steps\"][\"min_std\"] = cur_step_std[opt_energy_index]\n",
    "            if step_min_energy < cur_energy:\n",
    "                cur_energy = step_min_energy\n",
    "                cur_stddev = cur_step_std[opt_energy_index]\n",
    "                if param_index in [0, 1, 2]:\n",
    "                    multiplier = dt\n",
    "                else:\n",
    "                    multiplier = 1\n",
    "                cur_theta[param_index] = cur_theta[param_index] + \\\n",
    "                    parameter_search_space[str(param_index)][opt_energy_index] * multiplier\n",
    "            cur_dist_res_dict[\"steps\"][\"theta\"] = copy.deepcopy(cur_theta)\n",
    "            print(\"updated theta: \" + str(cur_theta))\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    opt_theta_index = values.index(np.min(values))\n",
    "\n",
    "    print(f\"Finished the VQE in {toc - tic:0.4f} seconds\")\n",
    "    print(\"final theta: \" + str(cur_theta))\n",
    "    print(\"min eigen_value found: \" + str(cur_energy))\n",
    "    print(\"absolute error: \" + str(np.abs(cur_energy - target_energy)))\n",
    "    print(\"std: \" + str(cur_stddev))\n",
    "    print(\"number of iterations: \" + str(i))\n",
    "    opt_sched = create_ansatz(cur_theta, dt, backend, layers=layers, qubits=qubits)\n",
    "    print(\"solution schedule duration: \" + str(opt_sched.duration * dt) + \" [ns]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "quantum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
